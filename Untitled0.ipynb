{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3ysCcZZZTn4AROWQFrC/I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LyungA/3719jung/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "O_-hZ0D7MRpp",
        "outputId": "f6e73933-ddf7-4d5c-eb56-676e2eef1ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['MCDONALD']: YFTzMissingError('possibly delisted; no timezone found')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-4685b98dc5d4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;31m# 선형 회귀 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# 예측할 미래 날짜 생성 (예시로 2023년 12월 31일까지)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         X, y = validate_data(\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1131\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression."
          ]
        }
      ],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# np.random.seed(10)\n",
        "# data = np.random.randn(50) * 10\n",
        "# data = np.append(data, [50, -40])\n",
        "# plt.boxplot(data)\n",
        "\n",
        "# plt.title(\"Box Plot with Outliers\")\n",
        "# plt.ylabel(\"Value\")\n",
        "# plt.show()\n",
        "\n",
        "# from sklearn.datasets import load_iris\n",
        "# import pandas as pd\n",
        "\n",
        "\n",
        "# iris = load_iris()\n",
        "\n",
        "# df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "# df['species'] = iris.target  # 품종 추가\n",
        "# df['species'] = df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
        "\n",
        "# df.head(5)\n",
        "\n",
        "\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "#import matplotlib.pyplot as plt\n",
        "#from sklearn.datasets import load_iris\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "#from sklearn.neighbors import KNeighborsClassifier\n",
        "#from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # 1️⃣ 아이리스 데이터 로드\n",
        "# iris = load_iris() # 150개\n",
        "# X = iris.data  # 특징 데이터 (꽃받침, 꽃잎의 길이와 너비)\n",
        "# y = iris.target  # 품종 (0: Setosa, 1: Versicolor, 2: Virginica)\n",
        "\n",
        "# # 2️⃣ 데이터 분할 (훈련 데이터 80%, 테스트 데이터 20%)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # 3️⃣ 데이터 스케일링 (KNN은 거리 기반 알고리즘이므로 정규화 필수)\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit_transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "\n",
        "# # 4️⃣ KNN 모델 학습 (K=5)\n",
        "# knn = KNeighborsClassifier(n_neighbors=120)\n",
        "# knn.fit(X_train, y_train)\n",
        "\n",
        "# # 5️⃣ 예측 및 평가\n",
        "# y_pred = knn.predict(X_test)\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print(f\"KNN 정확도: {accuracy:.4f}\")\n",
        "\n",
        "# # 6️⃣ 샘플 데이터 예측 (새로운 붓꽃 데이터 입력)\n",
        "# new_sample = np.array([[5.1, 3.5, 1.4, 0.2]])  # Setosa와 유사한 데이터\n",
        "# new_sample_scaled = scaler.transform(new_sample)\n",
        "# predicted_class = knn.predict(new_sample_scaled)\n",
        "# print(f\"예측된 품종: {iris.target_names[predicted_class][0]}\")\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1️⃣ 아이리스 데이터셋 로드\n",
        "# iris = datasets.load_iris()\n",
        "\n",
        "# # 2️⃣ 꽃잎의 길이와 너비 특성만 추출\n",
        "# X = iris.data[:, 2:]  # 꽃잎 길이와 꽃잎 너비\n",
        "# y = iris.target  # 실제 품종 정보\n",
        "\n",
        "# # 3️⃣ K-Means 클러스터링 모델 생성 (3개의 클러스터로 설정)\n",
        "# kmeans = KMeans(n_clusters=3, random_state=21)  # n_clusters=3은 3개의 군집으로 분할\n",
        "# kmeans.fit(X)  # KMeans 모델 학습\n",
        "\n",
        "# # 4️⃣ 예측된 클러스터 레이블\n",
        "# y_pred = kmeans.labels_  # KMeans 알고리즘이 예측한 클러스터 레이블\n",
        "\n",
        "# # 5️⃣ 군집의 중심점 추출\n",
        "# centers = kmeans.cluster_centers_  # 군집 중심점\n",
        "\n",
        "# # 6️⃣ 실제와 KMeans 예측 결과 비교 그래프 생성\n",
        "# fig, axes = plt.subplots(1, 2, figsize=(7, 3))  # 두 개의 서브 플롯\n",
        "\n",
        "# # 7️⃣ 실제 아이리스 데이터 산점도\n",
        "# axes[0].scatter(X[:, 0], X[:, 1], c=y, cmap='Set1_r', s=10)  # 실제 품종 레이블에 따른 색상\n",
        "# axes[0].set_xlabel('Petal length')  # x축 라벨\n",
        "# axes[0].set_ylabel('Petal width')  # y축 라벨\n",
        "# axes[0].set_title('Actual')  # 제목: 실제 값\n",
        "\n",
        "# # 8️⃣ K-Means 예측 결과 산점도\n",
        "# axes[1].scatter(X[:, 0], X[:, 1], c=y_pred, cmap='Set1', s=10)  # KMeans 예측값에 따른 색상\n",
        "# axes[1].set_xlabel('Petal length')  # x축 라벨\n",
        "# axes[1].set_ylabel('Petal width')  # y축 라벨\n",
        "# axes[1].set_title('Predicted')  # 제목: KMeans 예측 값\n",
        "\n",
        "# # 9️⃣ 군집의 중심점 표시\n",
        "# axes[1].scatter(centers[:, 0], centers[:, 1], c='blue', marker='x', s=50, label='Centroids')  # 군집 중심점\n",
        "# axes[1].legend()  # 범례 표시\n",
        "\n",
        "# # 10️⃣ 그래프 출력\n",
        "# plt.tight_layout()  # 그래프 간격 조정\n",
        "# plt.show()\n",
        "\n",
        "# !pip install yfinance --upgrade --no-cache-dir\n",
        "# !pip install matplotlib\n",
        "# !pip install scikit-learn\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "stock_data = yf.download('', start='2015-01-01', end='2025-01-01') # 애플\n",
        "stock_data.head()\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 날짜를 숫자로 변환 (단순히 날짜를 '일'로 처리)\n",
        "stock_data['Date'] = stock_data.index\n",
        "stock_data['Date'] = stock_data['Date'].map(pd.Timestamp.toordinal)\n",
        "\n",
        "# 종가와 날짜 데이터 준비\n",
        "X = stock_data['Date'].values.reshape(-1, 1)  # 독립 변수: 날짜\n",
        "y = stock_data['Close'].values  # 종속 변수: 종가\n",
        "\n",
        "# 선형 회귀 모델 학습\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# 예측할 미래 날짜 생성 (예시로 2023년 12월 31일까지)\n",
        "future_dates = pd.date_range(start='2020-01-01', periods=365*7, freq='D')\n",
        "future_dates_ordinal = future_dates.map(pd.Timestamp.toordinal).values.reshape(-1, 1)\n",
        "\n",
        "# 예측 결과\n",
        "predictions = model.predict(future_dates_ordinal)\n",
        "\n",
        "# 예측된 값과 실제 값을 비교하기 위한 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(stock_data.index, stock_data['Close'], label='Actual', color='blue')  # 실제 종가\n",
        "plt.plot(future_dates, predictions, label='Predicted', color='red')  # 예측 종가\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Close Price')\n",
        "plt.title('Stock Price Prediction using Linear Regression')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}